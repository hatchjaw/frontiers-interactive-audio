
@article{al-dhief_performance_2018,
	title = {Performance comparison between {TCP} and {UDP} protocols in different simulation scenarios},
	volume = {7},
	pages = {172--176},
	number = {4},
	journaltitle = {International Journal of Engineering \& Technology},
	author = {AL-Dhief, Fahad Taha and Sabri, Naseer and Latiff, NM Abdul and Malik, NNNA and Abbas, Musatafa and Albader, Abbood and Mohammed, Mazin Abed and AL-Haddad, Rami Noori and Salman, Yasir Dawood and Khanapi, Mohd and {others}},
	date = {2018},
	file = {AL-Dhief et al. - Performance Comparison between TCP and UDP Protoco.pdf:/home/tar/Zotero/storage/RMUXCI2W/AL-Dhief et al. - Performance Comparison between TCP and UDP Protoco.pdf:application/pdf},
}

@article{hardman_successful_1998,
	title = {Successful multiparty audio communication over the Internet},
	volume = {41},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/274946.274959},
	doi = {10.1145/274946.274959},
	pages = {74--80},
	number = {5},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Hardman, Vicky and Sasse, Martina Angela and Kouvelas, Isidor},
	urldate = {2022-12-19},
	date = {1998-05},
	langid = {english},
	file = {Hardman et al. - 1998 - Successful multiparty audio communication over the.pdf:/home/tar/Zotero/storage/M75BZNG4/Hardman et al. - 1998 - Successful multiparty audio communication over the.pdf:application/pdf},
}

@inproceedings{chafe_jacktrip_2019,
	title = {Jacktrip on Raspberry Pi},
	booktitle = {{LAC}-Linux Audio Conference},
	author = {Chafe, Chris and Oshiro, Scott},
	date = {2019},
	file = {Chafe and Oshiro - 2019 - Jacktrip on Raspberry Pi.pdf:/home/tar/Zotero/storage/B3TAYQ9I/Chafe and Oshiro - 2019 - Jacktrip on Raspberry Pi.pdf:application/pdf},
}

@article{bosi_experiencing_2021,
	title = {Experiencing Remote Classical Music Performance Over Long Distance: A {JackTrip} Concert Between Two Continents During the Pandemic},
	volume = {69},
	url = {https://www.aes.org/e-lib/browse.cfm?elib=21542},
	shorttitle = {Experiencing Remote Classical Music Performance Over Long Distance},
	abstract = {The recent lockdown restrictions imposed by the severe acute respiratory syndrome coronavirus 2 pandemic have heightened the need for new forms of remote collaboration for music schools, conservatories, musician ensembles, and artists, each of which would benefit from being provided with adequate tools to make high-quality, live collaborative music in a distributed fashion. This paper demonstrates the usage of the Networked Music Performance software {JackTrip} to support a distributed classical...},
	pages = {934--945},
	number = {12},
	journaltitle = {Journal of the Audio Engineering Society},
	shortjournal = {{JAES}},
	author = {Bosi, Marina and Servetti, Antonio and Chafe, Chris and Rottondi, Cristina},
	urldate = {2022-12-16},
	date = {2021-12-02},
	note = {Publisher: Audio Engineering Society},
	file = {Full Text PDF:/home/tar/Zotero/storage/QSI9YAAI/Bosi et al. - 2021 - Experiencing Remote Classical Music Performance Ov.pdf:application/pdf},
}

@article{chafe_i_2018,
	title = {I am Streaming in a Room},
	volume = {5},
	issn = {2297-2668},
	url = {https://www.frontiersin.org/articles/10.3389/fdigh.2018.00027},
	abstract = {Internet Acoustics is the study of sound traveling through the Internet, treating it as an acoustical medium just like air or water. Real-time streaming of sound, something commonplace nowadays, can be exploited for its own “physics” of propagation. In a digitally-connected telecommunication world, rooms of the kind which will be described enclose remotely collaborating musicians in their own reverberated sound. The ambience which results is the product of an acoustical loop which creates room-like resonances created between internet endpoints which recirculate sound echoes on the paths between them. These are synthesized acoustical spaces engineered to resemble actual rooms and distinct from other kinds of online rooms where “room” is used metaphorically for gatherings of users participating in teleconference or chat applications. The present article describes room-like internet reverberation for local area and wide area networking, respectively named {LAIR} and {WAIR}. Aspects of the medium, algorithms used and initial musical experiments are detailed. To support these topics, the article also presents a theory of operation for jacktrip, the low-latency internet streaming software which was modified for the project.},
	journaltitle = {Frontiers in Digital Humanities},
	author = {Chafe, Chris},
	urldate = {2022-12-16},
	date = {2018},
	file = {Full Text PDF:/home/tar/Zotero/storage/S6W46ZNK/Chafe - 2018 - I am Streaming in a Room.pdf:application/pdf},
}

@inproceedings{ferguson_trans-europe_2020,
	title = {Trans-Europe Express Audio: testing 1000 mile low-latency uncompressed audio between Edinburgh and Berlin using {GPS}-derived word clock, first with jacktrip then with Dante.},
	url = {https://www.aes.org/e-lib/browse.cfm?elib=20843},
	shorttitle = {Trans-Europe Express Audio},
	abstract = {For nearly two decades, networked audio research using jacktrip has shown that multi-channel uncompressed audio was possible over a National Research and Education Network ({NREN}) and was now becoming viable over some public network connections. There was however, a 'Dirty Secret', in the absence of any synchronisation between transmitting and receiving word clocks, periodic audio loss due to data over-run or over-run was a certainty. The authors describe a low-cost {GPS}-derived clocking...},
	eventtitle = {Audio Engineering Society Convention 148},
	publisher = {Audio Engineering Society},
	author = {Ferguson, Paul and Chafe, Chris and Gapp, Simon},
	urldate = {2022-12-16},
	date = {2020-05-28},
	file = {Full Text PDF:/home/tar/Zotero/storage/MHJPN3PZ/Ferguson et al. - 2020 - Trans-Europe Express Audio testing 1000 mile low-.pdf:application/pdf},
}

@article{mueller_acoustic_1971,
	title = {Acoustic holography},
	volume = {59},
	pages = {1319--1335},
	number = {9},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Mueller, Rolf K},
	date = {1971},
	note = {Publisher: {IEEE}},
	file = {mueller1971.pdf:/home/tar/Zotero/storage/IRC2UN66/mueller1971.pdf:application/pdf},
}

@article{fonseca_latency_2003,
	title = {Latency in Audio Ethernet Networks},
	abstract = {In a time when several audio Ethernet networking solutions are being studied and developed, the analysis of the latency introduced by theses networks is fundamental. This analysis is the subject of the present paper, and is necessary not only to enable the identification of the factors that can be optimised, but also to support the decision about the possibility or not of the inclusion of in-band synchronism signalling.},
	author = {Fonseca, Nuno and Monteiro, Edmundo},
	date = {2003},
	langid = {english},
	file = {Fonseca and Monteiro - 2003 - Latency in Audio Ethernet Networks.pdf:/home/tar/Zotero/storage/86AY9LHN/Fonseca and Monteiro - 2003 - Latency in Audio Ethernet Networks.pdf:application/pdf},
}

@article{caceres_jacktrip_2010,
	title = {{JackTrip}: Under the Hood of an Engine for Network Audio},
	volume = {39},
	issn = {0929-8215},
	url = {https://doi.org/10.1080/09298215.2010.481361},
	doi = {10.1080/09298215.2010.481361},
	shorttitle = {{JackTrip}},
	abstract = {The design of a platform for bi-directional musical performance using modern Wide area networks ({WANs}) poses several challenges that are different from related applications, e.g. synchronous local area network ({LAN}) studio systems or uni-directional {WAN} streaming. The need to minimize as much as possible audio latency and also maximize audio quality requires specific strategies which are informed, in part, by musical decisions. We present some of the key design elements of the {JackTrip} application which has evolved through several years of deployment in musical work over wide area networks.},
	pages = {183--187},
	number = {3},
	journaltitle = {Journal of New Music Research},
	author = {Cáceres, Juan-Pablo and Chafe, Chris},
	urldate = {2022-12-15},
	date = {2010-09-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09298215.2010.481361},
	file = {Full Text PDF:/home/tar/Zotero/storage/PIMGN793/Cáceres and Chafe - 2010 - JackTrip Under the Hood of an Engine for Network .pdf:application/pdf},
}

@inproceedings{gabrielli_networked_2012,
	title = {Networked Beagleboards for wireless music applications},
	doi = {10.1109/EDERC.2012.6532274},
	abstract = {One of the most demanding challenges in the field of audio engineering is the transmission of low-latency high quality audio streams over networks. While several protocols nowadays allow wired local network streaming, much effort is still required to achieve similar goals over existing wireless {LAN} technologies. While the challenge is still far from being solved, several design issues can be highlighted and future scenarios can be outlined. This paper proposes the setup of a wireless music production system based on open hardware and open software which requires relatively low setup effort while allowing for a high flexibility of use. The hardware platform is the Beagleboard, based on Texas Instruments {DM}3730, running a {GNU}/Linux {OS} and the computer music language Pure Data. Such a device can capture electric instrument audio, generate sound, send {MIDI} or {OSC} control data, and stream to {PCs} and other embedded devices operating as mixers, effect racks and so on, enabling an ecosystem of flexible and open devices. Tests conducted on a home wireless network show acceptable latency for many applications.},
	eventtitle = {2012 5th European {DSP} Education and Research Conference ({EDERC})},
	pages = {291--295},
	booktitle = {2012 5th European {DSP} Education and Research Conference ({EDERC})},
	author = {Gabrielli, Leonardo and Squartini, Stefano and Principi, Emanuele and Piazza, Francesco},
	date = {2012-09},
	file = {Gabrielli et al. - 2012 - Networked Beagleboards for wireless music applicat.pdf:/home/tar/Zotero/storage/3X4EH3ZT/Gabrielli et al. - 2012 - Networked Beagleboards for wireless music applicat.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tar/Zotero/storage/PFYJYSGU/6532274.html:text/html},
}

@inproceedings{ahrens_theory_2008,
	title = {The Theory of Wave Field Synthesis Revisited},
	url = {https://www.aes.org/e-lib/browse.cfm?elib=14488},
	abstract = {Wave field synthesis is a spatial sound field reproduction technique aiming at authentic reproduction of auditory scenes. Its theoretical foundation has been developed almost 20 years ago and has been improved considerably since then. Most of the original work on wave field synthesis is restricted to the reproduction in a planar listening area using linear loudspeaker arrays. Extensions like arbitrarily shaped distributions of secondary sources and three-dimensional reproduction in a listening...},
	eventtitle = {Audio Engineering Society Convention 124},
	publisher = {Audio Engineering Society},
	author = {Ahrens, Jens and Rabenstein, Rudolph and Spors, Sascha},
	urldate = {2022-12-15},
	date = {2008-05-01},
	file = {Ahrens et al. - 2008 - The Theory of Wave Field Synthesis Revisited.pdf:/home/tar/Zotero/storage/77CKWIHL/Ahrens et al. - 2008 - The Theory of Wave Field Synthesis Revisited.pdf:application/pdf},
}

@article{berkhout_acoustic_1993,
	title = {Acoustic control by wave field synthesis},
	volume = {93},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.405852},
	doi = {10.1121/1.405852},
	pages = {2764--2778},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Berkhout, A. J. and de Vries, D. and Vogel, P.},
	urldate = {2022-12-15},
	date = {1993},
	note = {Publisher: Acoustical Society of America},
	file = {Berkhout et al. - 1993 - Acoustic control by wave field synthesis.pdf:/home/tar/Zotero/storage/WJIKRXM8/Berkhout et al. - 1993 - Acoustic control by wave field synthesis.pdf:application/pdf},
}

@article{turletti_inria_1995,
	title = {The {INRIA} videoconferencing system ({IVS})},
	volume = {8},
	abstract = {Introduction {IVS} is a software system to transmit audio and video data over the Internet. It includes {PCM} and {ADPCM} audio codecs, as well as a H.261 [H.261] codec. Both audio and video codecs are software codecs. The H.261 video coding standard was originally designed for the transmission of video flows over fixed-bandwidth lines, i.e. leased lines or switched circuits for data transmission. In order to use this video coding over packet switched networks such as the Internet, a packetization scheme is required. This scheme must take into account the hierarchical structure of H.261 images. Furthermore, packet loss recovery and flow control schemes are also required to send video over the Internet. We next briefly describe the H.261 coding standard. We then present the video packetization scheme and the error and flow control schemes we developed for the Internet environment. We then describe different applications using {IVS}. We conclude with practical details regarding {IVS}, in},
	journaltitle = {{ConeXions}},
	shortjournal = {{ConeXions}},
	author = {Turletti, Thierry},
	date = {1995-01-22},
	file = {Turletti - 1995 - The INRIA videoconferencing system (IVS).pdf:/home/tar/Zotero/storage/HBSYCQ9Q/Turletti - 1995 - The INRIA videoconferencing system (IVS).pdf:application/pdf},
}

@inproceedings{ahrens_implementation_2007,
	title = {Implementation of Directional Sources Inwave Field Synthesis},
	doi = {10.1109/ASPAA.2007.4393024},
	abstract = {Wave field synthesis ({WFS}) is a spatial audio reproduction technique aiming at physically synthesizing a desired sound field. Typically, virtual sound sources are rendered as emitting spherical or plane waves. In this paper we present an approach to the implementation of sources with arbitrary directivity. The approach is based on the description of the directional properties of a source by a set of circular harmonics. A time domain expression of the loudspeaker driving signals is derived allowing an efficient implementation. Consequences of sampling and truncation of the secondary source distribution as occurring in typical installations of {WFS} systems are discussed and simulated reproduction results are shown.},
	eventtitle = {2007 {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics},
	pages = {66--69},
	booktitle = {2007 {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics},
	author = {Ahrens, Jens and Spors, Sascha},
	date = {2007-10},
	note = {{ISSN}: 1947-1629},
	keywords = {Acoustic applications, Acoustic signal processing, Conferences, Frequency domain analysis, Geometry, Layout, Loudspeakers, Psychoacoustic models, Signal synthesis, Vectors},
	file = {Ahrens and Spors - 2007 - Implementation of Directional Sources Inwave Field.pdf:/home/tar/Zotero/storage/H5F3RHUP/Ahrens and Spors - 2007 - Implementation of Directional Sources Inwave Field.pdf:application/pdf;IEEE Xplore Abstract Record:/home/tar/Zotero/storage/Z8JKM8C4/4393024.html:text/html},
}

@inproceedings{michon_real_2019,
	location = {Malaga, Spain},
	title = {Real Time Audio Digital Signal Processing With Faust and the Teensy},
	url = {https://hal.archives-ouvertes.fr/hal-03153709},
	booktitle = {Sound and Music Computing Conference ({SMC}-19)},
	author = {Michon, Romain and Orlarey, Yann and Letz, Stéphane and Fober, Dominique},
	urldate = {2022-12-15},
	date = {2019-05},
	file = {HAL PDF Full Text:/home/tar/Zotero/storage/KN9JSTH9/Michon et al. - 2019 - Real Time Audio Digital Signal Processing With Fau.pdf:application/pdf},
}

@inproceedings{schiavoni_alternatives_2013,
	title = {Alternatives in network transport protocols for audio streaming applications},
	booktitle = {{ICMC}},
	author = {Schiavoni, Flávio Luiz and Queiroz, Marcelo and Wanderley, Marcelo M},
	date = {2013},
	file = {Schiavoni et al. - 2013 - Alternatives in network transport protocols for au.pdf:/home/tar/Zotero/storage/FK5QVEUD/Schiavoni et al. - 2013 - Alternatives in network transport protocols for au.pdf:application/pdf},
}

@article{marouani_internal_2008,
	title = {Internal Clock Drift Estimation in Computer Clusters},
	volume = {2008},
	issn = {2090-7141},
	url = {https://www.hindawi.com/journals/jcnc/2008/583162/},
	doi = {10.1155/2008/583162},
	abstract = {Most computers have several high-resolution timing sources, from the programmable interrupt timer to the cycle counter. Yet, even at a precision of one cycle in ten millions, clocks may drift significantly in a single second at a clock frequency of several {GHz}. When tracing the low-level system events in computer clusters, such as packet sending or reception, each computer system records its own events using an internal clock. In order to properly understand the global system behavior and performance, as reported by the events recorded on each computer, it is important to estimate precisely the clock differences and drift between the different computers in the system. This article studies the clock precision and stability of several computer systems, with different architectures. It also studies the typical network delay characteristics, since time synchronization algorithms rely on the exchange of network packets and are dependent on the symmetry of the delays. A very precise clock, based on the atomic time provided by the {GPS} satellite network, was used as a reference to measure clock drifts and network delays. The results obtained are of immediate use to all applications which depend on computer clocks or network time synchronization accuracy.},
	pages = {e583162},
	journaltitle = {Journal of Computer Networks and Communications},
	author = {Marouani, Hicham and Dagenais, Michel R.},
	urldate = {2022-12-15},
	date = {2008-05-29},
	langid = {english},
	note = {Publisher: Hindawi},
	file = {Full Text PDF:/home/tar/Zotero/storage/CWBAH8TM/Marouani and Dagenais - 2008 - Internal Clock Drift Estimation in Computer Cluste.pdf:application/pdf},
}

@article{caceras_jacktripsoundwire_2010,
	title = {{JackTrip}/{SoundWIRE} Meets Server Farm},
	volume = {34},
	issn = {0148-9267},
	url = {https://www.jstor.org/stable/40963030},
	pages = {29--34},
	number = {3},
	journaltitle = {Computer Music Journal},
	author = {Cáceras, Juan-Pablo and Chafe, Chris},
	urldate = {2022-12-15},
	date = {2010},
	note = {Publisher: The {MIT} Press},
	file = {Cáceras and Chafe - 2010 - JackTripSoundWIRE Meets Server Farm.pdf:/home/tar/Zotero/storage/XJ4UZ3N9/Cáceras and Chafe - 2010 - JackTripSoundWIRE Meets Server Farm.pdf:application/pdf},
}

@inproceedings{chafe_physical_2002,
	title = {Physical model synthesis with application to Internet acoustics},
	volume = {4},
	doi = {10.1109/ICASSP.2002.5745548},
	abstract = {Distributed physical models of musical instruments have been used to acoustically “ping” Internet connections between two network hosts. Sound waves propagated through Internet acoustics behave just as in air, water or along a stretched string. In this case, a musical synthesis technique creates waves on the Internet path between two hosts. When waves recirculate between two endpoints, a musical tone is created if the round trip travel time lies within the range of our pitch sense (roughly 250µs to 50ms). The resulting tones provide a quick and intuitive evaluation of quality of service ({QoS}), displaying its significant aspects including latency, jitter and packet loss. Stable, clear tones with high pitch indicate good end-to-end capabilities that a path must support for immersive, real-time applications. A “network harp” recently demonstrated 320 synthesized strings oscillating across the Western half of the Internet2 Abilene Network.},
	eventtitle = {2002 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	pages = {IV--4056--IV--4059},
	booktitle = {2002 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	author = {Chafe, Chris and Wilson, Scott and Walling, Daniel},
	date = {2002-05},
	note = {{ISSN}: 1520-6149},
	keywords = {Acoustics, Artificial neural networks, Delay, Instruments, Internet, Servers, Wire},
	file = {IEEE Xplore Abstract Record:/home/tar/Zotero/storage/LLVTD4UW/5745548.html:text/html;Submitted Version:/home/tar/Zotero/storage/NMBXHE6P/Chafe et al. - 2002 - Physical model synthesis with application to Inter.pdf:application/pdf},
}

@inproceedings{lopez-lezcano_jack_2012,
	title = {From Jack to {UDP} packets to sound and back},
	volume = {2012},
	booktitle = {Proceedings of the Linux Audio Conference},
	author = {Lopez-Lezcano, Fernando},
	date = {2012},
	file = {Lopez-Lezcano - 2012 - From Jack to UDP packets to sound and back.pdf:/home/tar/Zotero/storage/IIEELN3N/Lopez-Lezcano - 2012 - From Jack to UDP packets to sound and back.pdf:application/pdf},
}

@book{roads_computer_1996,
	title = {The Computer Music Tutorial},
	publisher = {{MIT} press},
	author = {Roads, Curtis},
	date = {1996},
}

@article{de_poli_physically_1998,
	title = {Physically based sound modelling},
	volume = {3},
	issn = {13557718},
	url = {http://www.journals.cambridge.org/abstract_S1355771898009182},
	doi = {10.1017/S1355771898009182},
	pages = {61--76},
	number = {1},
	journaltitle = {Organised Sound},
	shortjournal = {Org. Sound},
	author = {De Poli, Giovnni and Rocchesso, Davide},
	urldate = {2022-02-10},
	date = {1998-04},
	langid = {english},
	file = {De Poli and Rocchesso - 1998 - Physically based sound modelling.pdf:/home/tar/Zotero/storage/KB4KVLAM/De Poli and Rocchesso - 1998 - Physically based sound modelling.pdf:application/pdf},
}

@video{juce_simultaneous_2022,
	title = {Simultaneous Audio Playback/capture on Multiple Interfaces, Devices and/or Networks - {ADC}21},
	url = {https://www.youtube.com/watch?v=8jHLusUVa2Y},
	abstract = {Slides: https://data.audio.dev/talks/2021/syn...
https://audio.dev/ -- @audiodevcon
Organized and produced by {JUCE}: https://juce.com/
---
Synchronizing Clocks - Simultaneous Audio Playback/capture on Multiple Interfaces, Devices and/or Networks

We all know how to play/capture audio from a single audio interface with our favourite audio {API}. But how do you play/capture audio synchronously across multiple audio interfaces, computers, local networks or even the internet? The basic principle is always the same and can roughly be split into three distinct tasks:

1. Query the current presentation/capture time of each audio interface
2. Predict and convert between presentation/capture times of different clock domains using mathematical models
3. Control the playback/capture rate of each audio interface.

After a brief introduction, this talk will examine each of the above tasks in detail and how various algorithms and techniques apply to different synchronisation applications. The listener will benefit from a practical focus, by learning how various industry standards approach the problem ({AVB}, {AirPlay}, {RTP}, …), which {APIs} are available on different platforms and various practical considerations when using {WiFi} and/or ethernet as a transport to synchronise audio.

The talk will end with a case study on how the author helped achieve less than 10μs audio playback/capture synchronisation accuracy via {WiFi} on the Syng Cell Alpha.

---
Fabian Renn-Giles

Fabian is a freelance C++ programmer, entrepreneur and consultant in the audio software industry. Before this, he was staff engineer at {ROLI} Ltd. and the lead maintainer/developer of the {JUCE} C++ framework (www.juce.com) - an audio framework used by thousands of commercial audio software companies. Before joining {ROLI}, he completed his {PhD} at Imperial College London, developing a numerical quantum optics solver with modern digital signal processing techniques and C++/{MPI}/{OpenCL}. During his academic career, Fabian regularly taught C++ to post- and undergraduate students in tutor groups. In 2005, Fabian co-founded the audio plug-in start-up Fielding {DSP} which specialises in real-time audio plug-ins for audio mastering. Fabian now regularly consults on various audio related software projects. Additionally, he is a regular speaker and/or workshop leader at the audio developer conference {ADC}.

---
Streamed \& Edited by Digital Medium Ltd - online.digital-medium.co.uk

---
Special thanks to the {ADC}21 Team:

Lina Berzinskas
Sophie Carus
Timur Doumler 
Derek Heimlich 
Josh Hodge 
Andrew Kirk
Bobby Lombardi
Top Poole
Ralph Richbourg
Jim Roper
Jonathan Roper},
	author = {{JUCE}},
	urldate = {2023-08-12},
	date = {2022-07-14},
}

@inproceedings{adriaensen_using_2005,
	title = {Using a {DLL} to filter time},
	booktitle = {Linux audio conference},
	author = {Adriaensen, Fons},
	date = {2005},
	file = {Adriaensen - Using a DLL to ﬁlter time.pdf:/home/tar/Zotero/storage/9ZG5WK8B/Adriaensen - Using a DLL to ﬁlter time.pdf:application/pdf},
}

@online{noauthor_jacktrip_nodate,
	title = {{JackTrip}},
	url = {https://jacktrip.github.io/jacktrip/},
	urldate = {2023-06-09},
	file = {JackTrip:/home/tar/Zotero/storage/8CB4K2JJ/jacktrip.html:text/html},
}

@online{noauthor_teensy_nodate,
	title = {Teensy {USB} Development Board},
	url = {https://www.pjrc.com/teensy/},
	urldate = {2023-06-08},
	file = {Teensy USB Development Board:/home/tar/Zotero/storage/UXGIDBAJ/teensy.html:text/html},
}

@thesis{paisa_wavefield_2016,
	title = {Wavefield Synthesis for Max/{MSP}},
	type = {phdthesis},
	author = {Paisa, Razvan},
	date = {2016},
	langid = {english},
	file = {Paisa - Wavefield Synthesis for MaxMSP.pdf:/home/tar/Zotero/storage/UBSXHXQT/Paisa - Wavefield Synthesis for MaxMSP.pdf:application/pdf},
}

@misc{lago_distributed_2004,
	title = {Distributed Real-Time Audio Processing},
	abstract = {Computer systems for real-time multimedia processing require high processing power. Problems that depend on high processing power are usually solved by using parallel or distributed computing techniques; however, the combination of the diﬃculties of both real-time and parallel programming has led the development of applications for real-time multimedia processing for general purpose computer systems to be based on centralized and single-processor systems. In several systems for multimedia processing, there is a need for low latency during the interaction with the user, which reinforces the tendency towards single-processor development.},
	author = {Lago, Nelson Posse},
	date = {2004},
	langid = {english},
	file = {Lago - Distributed Real-Time Audio Processing.pdf:/home/tar/Zotero/storage/JG4MHPVA/Lago - Distributed Real-Time Audio Processing.pdf:application/pdf},
}

@inproceedings{sacchetto_jacktrip-webrtc_2021,
	title = {{JackTrip}-{WebRTC}: Networked music experiments with {PCM} stereo audio in a Web browser},
	abstract = {A large number of web applications are available for videoconferencing and those have been very helpful during the lockdown periods caused by the {COVID}-19 pandemic. However, none of these oﬀer high ﬁdelity stereo audio for music performance, mainly because the current {WebRTC} {RTCPeerConnection} standard only supports compressed audio formats. This paper presents the results achieved implementing 16-bit {PCM} stereo audio transmission on top of the {WebRTC} {RTCDataChannel} with the help of Web Audio and {AudioWorklets}. Several measurements with diﬀerent conﬁgurations, browsers, and operating systems are presented. They show that, at least on the loopback network interface, this approach can achieve better quality and lower latency than using {RTCPeerConnection}, for example, latencies as low as 50-60 ms have been achieved on {MacOS}.},
	booktitle = {Web Audio Conference {WAC}-2021},
	author = {Sacchetto, Matteo and Servetti, Antonio and Chafe, Chris},
	date = {2021},
	langid = {english},
	file = {Sacchetto et al. - JackTrip-WebRTC Networked music experiments with .pdf:/home/tar/Zotero/storage/8JRQ7UPY/Sacchetto et al. - JackTrip-WebRTC Networked music experiments with .pdf:application/pdf},
}

@inproceedings{renaud_networked_2012,
	title = {Networked Music Performance : State of the Art},
	shorttitle = {{NETWORKED} {MUSIC} {PERFORMANCE}},
	booktitle = {{AES} 30th International Conference},
	author = {Renaud, Alain and Carôt, Alexander and Rebelo, Pedro},
	date = {2012-01-01},
	file = {Full Text PDF:/home/tar/Zotero/storage/QSP39YKA/Renaud et al. - 2012 - NETWORKED MUSIC PERFORMANCE  STATE OF THE ART.pdf:application/pdf},
}

@misc{carot_netjack_2009,
	title = {Netjack – Remote music collaboration with electronic sequencers on the Internet},
	abstract = {The {JACK} audio server with its ability to process audio streams of numerous applications with realtime priority, has major signiﬁcance in context with audio processing on Linux driven personal computers. Although the Soundjack and the Jacktrip project already use {JACK} in terms of remote handmade music collaboration, there is currently no technology available, which supports the interconnection of electronic music sequencers. This paper introduces the Netjack tool, which achieves sample accurate timeline synchronization by applying the delayed feedback approach ({DFA}) and in turn represents the ﬁrst solution towards this goal.},
	author = {Carôt, Alexander and Hohn, Torben and Werner, Christian},
	date = {2009-01-01},
	langid = {english},
	file = {Carôt et al. - Netjack – Remote music collaboration with electron.pdf:/home/tar/Zotero/storage/ADW7XJV8/Carot et al. - Netjack – Remote music collaboration with electron.pdf:application/pdf},
}

@inproceedings{chafe_simplified_2000,
	title = {A Simplified Approach to High Quality Music and Sound Over {IP}},
	abstract = {Present systems for streaming digital audio between devices connected by internet have been limited by a number of compromises. Because of restricted bandwidth and “best effort” delivery, signal compression of one form or another is typical. Buffering of audio data which is needed to safeguard against delivery uncertainties can cause signal delays of seconds. Audio is in general an unforgiving test of networking, e.g., one data packet arriving too late and we hear it. Trade-offs of signal quality have been necessary to avoid this basic fact and until now, have vied against serious musical uses.},
	booktitle = {Proceedings of the {COST} G-6 Conference on Digital Audio Effects ({DAFX}-00)},
	author = {Chafe, Chris and Wilson, Scott and Leistikow, Randal and Chisholm, Dave and Scavone, Gary},
	date = {2000},
	langid = {english},
	file = {Chafe et al. - 2000 - A SIMPLIFIED APPROACH TO HIGH QUALITY MUSIC AND SO.pdf:/home/tar/Zotero/storage/4VG85HTK/Chafe et al. - 2000 - A SIMPLIFIED APPROACH TO HIGH QUALITY MUSIC AND SO.pdf:application/pdf},
}

@report{schulzrinne_voice_1992,
	title = {Voice communication across the Internet: A network voice terminal},
	institution = {University of Massachusetts at Amherst, Department of Computer and Information Science},
	author = {Schulzrinne, Henning},
	date = {1992},
	file = {UM-CS-1992-050.pdf:/home/tar/Zotero/storage/9KYXX5U9/UM-CS-1992-050.pdf:application/pdf},
}

@online{noauthor_socket2_nodate,
	title = {socket(2) - Linux manual page},
	url = {https://man7.org/linux/man-pages/man2/socket.2.html},
	urldate = {2023-05-24},
	file = {socket(2) - Linux manual page:/home/tar/Zotero/storage/GHBG4SBS/socket.2.html:text/html},
}

@misc{winett_rfc0147_1971,
	title = {{RFC}0147: Definition of a Socket},
	author = {Winett, Joel M},
	date = {1971},
	langid = {english},
	file = {Winett - The Definition of a Socket.pdf:/home/tar/Zotero/storage/J8L9RYCG/Winett - The Definition of a Socket.pdf:application/pdf},
}

@inproceedings{rushton_microcontroller-based_2023,
	title = {A Microcontroller-based Network Client Towards Distributed Spatial Audio},
	abstract = {Audio spatialisation techniques such as wave field synthesis call for the deployment of large arrays of loudspeakers, typically managed by dedicated audio hardware. Such systems are typically costly, inflexible, and limited by the computational demands and high throughput requirements of centralised, highly-multichannel digital signal processing. The development of a distributed system for audio spatialisation based on Audio over Ethernet represents a potential easing of the infrastructural burdens posed by traditional, centralised approaches. This work details the development of a networked audio client, supporting the popular {JackTrip} audio protocol, and running on a low-cost microcontroller. The system is applied to the case of a wave field synthesis installation, with a number of client instances forming a distributed array of signal processors. The problems of client-server latency, and interclient synchronicity are discussed and a mitigative strategy described. The client software and hardware modules could support large scale audio installations, plus serve as self-contained interfaces for other networked audio applications.},
	booktitle = {Sound and Music Computing Conference ({SMC}-23)},
	author = {Rushton, Thomas Albert and Michon, Romain and Letz, Stéphane},
	date = {2023},
	langid = {english},
	file = {Rushton and Michon - A MICROCONTROLLER-BASED NETWORK CLIENT TOWARDS DIS.pdf:/home/tar/Zotero/storage/I5D344ZX/Rushton and Michon - A MICROCONTROLLER-BASED NETWORK CLIENT TOWARDS DIS.pdf:application/pdf},
}

@inproceedings{devonport_distribution_2019,
	title = {The Distribution of Ambisonic and Point Source Rendering to Ethernet {AVB} Speakers},
	abstract = {Point source rendering is used by many object-based audio systems to mix audio objects to loudspeaker arrangements. Algorithms such as Distance-Based Amplitude Panning and Vector-Base Amplitude Panning allow for audio objects to have their locations rendered with high precision. It has been shown that in the context of loudspeaker rendering, point sources rendered with Ambisonics are often spatially blurred. However, Ambisonics does have the advantage of being able to create interesting spatial audio effects and ambient scenes can be recorded using Ambisonic microphones. This paper intends to highlight the advantages that may be gained by combining Ambisonics with virtual point source rendering. It is well known that the processing required for rendering both point source and Ambisonics can have a large overhead. To mitigate this, a distributed spatial audio system based on Ethernet {AVB} and distributed endpoint processors is modified to incorporate both point source rendering and Ambisonics. An example is given of how point source rendering can be integrated with Ambisonics using this system with existing software.},
	booktitle = {5th International Conference on Spatial Audio},
	author = {Devonport, Sean and Foss, Richard},
	date = {2019},
	langid = {english},
	keywords = {{AVB}, Distributed},
	file = {Devonport and Foss - 2019 - The Distribution of Ambisonic and Point Source Ren.pdf:/home/tar/Zotero/storage/7WY4CVUN/Devonport and Foss - 2019 - The Distribution of Ambisonic and Point Source Ren.pdf:application/pdf},
}

@report{meyer_iana_2010,
	title = {{IANA} Guidelines for {IPv}4 Multicast Address Assignments},
	url = {https://datatracker.ietf.org/doc/rfc5771},
	abstract = {This document provides guidance for the Internet Assigned Numbers Authority ({IANA}) in assigning {IPv}4 multicast addresses. It obsoletes {RFC} 3171 and {RFC} 3138 and updates {RFC} 2780. This memo documents an Internet Best Current Practice.},
	number = {{RFC} 5771},
	institution = {Internet Engineering Task Force},
	type = {Request for Comments},
	author = {Meyer, David and Cotton, Michelle and Vegoda, Leo},
	urldate = {2023-05-19},
	date = {2010-03},
	doi = {10.17487/RFC5771},
	note = {Num Pages: 11},
	file = {Full Text PDF:/home/tar/Zotero/storage/FD8IZ3ZR/Meyer et al. - 2010 - IANA Guidelines for IPv4 Multicast Address Assignm.pdf:application/pdf},
}

@article{berkhout_holographic_1988,
	title = {A Holographic Approach to Acoustic Control},
	volume = {36},
	url = {https://www.aes.org/e-lib/browse.cfm?elib=5117},
	abstract = {In the past the temporal aspects of sound fields have obtained considerably more attention than the spatial aspects. Therefore most electroacoustic arguments are based on temporal frequencies and temporal reflection sequences. It is shown that sound control should be based on 'acoustic holography,' featuring the spatial reconstruction of direct and reflected wave fields with desired wavefront properties at each moment of time. As holographically reconstructed sound fields cannot be...},
	pages = {977--995},
	number = {12},
	journaltitle = {Journal of the Audio Engineering Society},
	shortjournal = {{JAES}},
	author = {Berkhout, A. J.},
	urldate = {2023-05-18},
	date = {1988-12-01},
	note = {Publisher: Audio Engineering Society},
}

@article{vogel_application_1993,
	title = {Application of Wave Field Synthesis in Room Acoustics},
	url = {https://repository.tudelft.nl/islandora/object/uuid%3A4d236099-096e-444c-bf40-b7b163076bf6},
	author = {Vogel, P.},
	urldate = {2023-05-18},
	date = {1993},
	langid = {english},
	file = {Full Text PDF:/home/tar/Zotero/storage/CW3D778S/Vogel - 1993 - Application of Wave Field Synthesis in Room Acoust.pdf:application/pdf},
}

@article{verheijen_sound_1998,
	title = {Sound reproduction by wave field synthesis},
	url = {https://repository.tudelft.nl/islandora/object/uuid%3A9a35b281-f19d-4f08-bec7-64f6920a3821},
	author = {Verheijen, E. N. G.},
	urldate = {2023-05-18},
	date = {1998},
	langid = {english},
	file = {Full Text PDF:/home/tar/Zotero/storage/9WQTGVCY/Verheijen - 1998 - Sound reproduction by wave field synthesis.pdf:application/pdf},
}

@inbook{ziemer_wave_2020,
	location = {Cham},
	title = {Wave Field Synthesis},
	volume = {7},
	isbn = {978-3-030-23032-6 978-3-030-23033-3},
	url = {http://link.springer.com/10.1007/978-3-030-23033-3_8},
	pages = {203--243},
	booktitle = {Psychoacoustic Music Sound Field Synthesis},
	publisher = {Springer International Publishing},
	author = {Ziemer, Tim},
	bookauthor = {Ziemer, Tim},
	urldate = {2023-05-17},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-23033-3_8},
	note = {Series Title: Current Research in Systematic Musicology},
	file = {Ziemer - 2020 - Wave Field Synthesis.pdf:/home/tar/Zotero/storage/GVU8J7L4/Ziemer - 2020 - Wave Field Synthesis.pdf:application/pdf},
}

@article{spors_comparison_2008,
	title = {A Comparison of Wave Field Synthesis and Higher-Order Ambisonics with Respect to Physical Properties and Spatial Sampling},
	abstract = {Wave ﬁeld synthesis ({WFS}) and higher-order Ambisonics ({HOA}) are two high-resolution spatial sound reproduction techniques aiming at overcoming some of the limitations of stereophonic reproduction techniques. In the past, the theoretical foundations of {WFS} and {HOA} have been formulated in a quite diﬀerent fashion. Although, some work has been published that aims at comparing both approaches their similarities and diﬀerences are not well documented. This paper formulates the theory of both approaches in a common framework, highlights the diﬀerent assumptions made to derive the driving functions and the resulting physical properties of the reproduced wave ﬁeld. Special attention will be drawn to the consequences of spatial sampling since both approaches diﬀer signiﬁcantly here.},
	author = {Spors, Sascha and Ahrens, Jens},
	date = {2008},
	langid = {english},
	file = {Spors and Ahrens - 2008 - A Comparison of Wave Field Synthesis and Higher-Or.pdf:/home/tar/Zotero/storage/6SZIJHF7/Spors and Ahrens - 2008 - A Comparison of Wave Field Synthesis and Higher-Or.pdf:application/pdf},
}

@inproceedings{naef_spatialized_2002,
	location = {Hong Kong China},
	title = {Spatialized audio rendering for immersive virtual environments},
	isbn = {978-1-58113-530-5},
	url = {https://dl.acm.org/doi/10.1145/585740.585752},
	doi = {10.1145/585740.585752},
	eventtitle = {{VRST}02: The {ACM} Symposium on Virtual Reality Software and Technology 2002},
	pages = {65--72},
	booktitle = {Proceedings of the {ACM} symposium on Virtual reality software and technology},
	publisher = {{ACM}},
	author = {Naef, Martin and Staadt, Oliver and Gross, Markus},
	urldate = {2023-05-16},
	date = {2002-11-11},
	langid = {english},
	file = {Full Text:/home/tar/Zotero/storage/QF4KYGP2/Naef et al. - 2002 - Spatialized audio rendering for immersive virtual .pdf:application/pdf},
}

@online{mitterhuber_ottosonics_nodate,
	title = {Ottosonics},
	url = {https://tamlab.kunstuni-linz.at/projects/ottosonics/},
	abstract = {Project financed by the “Neustart Kultur” program – (Bundesministerium für Kunst und Kultur) in 2022. Website of the Ottosonics project in Alter Bauhof Description {OTTOsonics} is a collective project by sounds-artists, developers, scholars and sound engineers working on accessible audio technologies for immersive sound creation. Putting the focus on the needs of performance artists as …},
	titleaddon = {Tangible Music Lab},
	author = {Mitterhuber, Manu and Sharaﬁ, Rojin and Tomás, Enrique},
	urldate = {2023-05-04},
	langid = {american},
	file = {Mitterhuber et al. - Ottosonics.pdf:/home/tar/Zotero/storage/E5GY5I9X/Mitterhuber et al. - Ottosonics.pdf:application/pdf;Snapshot:/home/tar/Zotero/storage/H52ZLRSW/ottosonics.html:text/html},
}

@online{fischer_case_2015,
	title = {Case Study: Performing Band Rehearsals on the Internet With Jamulus},
	url = {https://jamulus. io/PerformingBandRehearsalsontheInternetWithJamulus. pdf},
	author = {Fischer, Volker},
	date = {2015},
	file = {Fischer - Case Study Performing Band Rehearsals on the Inte.pdf:/home/tar/Zotero/storage/R69P7EAF/Fischer - Case Study Performing Band Rehearsals on the Inte.pdf:application/pdf},
}

@report{bakker_introduction_2014,
	title = {An introduction to networked audio},
	institution = {Yamaha Commercial Audio Team},
	type = {White Paper},
	author = {Bakker, Ron and Cooper, Andy and Kitagawa, Atsushi},
	date = {2014},
	langid = {english},
	file = {Audio - An introduction to networked audio.pdf:/home/tar/Zotero/storage/KKFAW7XT/Audio - An introduction to networked audio.pdf:application/pdf},
}

@inproceedings{lim_performance_2012,
	title = {Performance Analysis of the {IEEE} 802.1 Ethernet Audio/Video Bridging Standard},
	doi = {10.4108/icst.simutools.2012.247747},
	abstract = {Switched Ethernet is widely used for all kinds of applications. However, for demanding multimedia streaming applications in a fully-loaded network, legacy Ethernet is not the best choice due to its limited Quality-of-Service ({QoS}) support. The new specification of the {IEEE} 802.1 Audio/Video Bridging ({AVB}) standard, an extension to legacy Ethernet, provides the {QoS} features needed for multimedia streaming: Time synchronized low latency streaming services and bandwidth reservation on Layer-2. In this work, we study and analyze the {AVB} standard based on a simulation approach to verify the specified constraints and to determine the feasibility of the mechanisms in a switched Ethernet network. We use the simulation tool {OMNeT}++ and extend the existing {INET}-framework to support all the required protocols specified in the {IEEE} 802.1 {AVB} standard.},
	pages = {27--36},
	author = {Lim, Hyung-Taek and Herrscher, Daniel and Waltl, Martin and Chaari, Firas},
	date = {2012-03-19},
	file = {Full Text:/home/tar/Zotero/storage/KEHXRQJP/Lim et al. - 2012 - Performance Analysis of the IEEE 802.1 Ethernet Au.pdf:application/pdf},
}

@report{cohen_specifications_1977,
	title = {Specifications for the Network Voice Protocol ({NVP})},
	url = {https://www.rfc-editor.org/info/rfc0741},
	pages = {RFC0741},
	number = {{RFC}0741},
	institution = {{RFC} Editor},
	author = {Cohen, D.},
	urldate = {2023-05-15},
	date = {1977-11},
	langid = {english},
	doi = {10.17487/rfc0741},
	file = {Cohen - 1977 - Specifications for the Network Voice Protocol (NVP.pdf:/home/tar/Zotero/storage/9DU4YKWQ/Cohen - 1977 - Specifications for the Network Voice Protocol (NVP.pdf:application/pdf},
}

@book{kshemkalyani_distributed_2011,
	title = {Distributed Computing: Principles, Algorithms, and Systems},
	isbn = {978-1-139-47031-5},
	shorttitle = {Distributed Computing},
	abstract = {Designing distributed computing systems is a complex process requiring a solid understanding of the design problems and the theoretical and practical aspects of their solutions. This comprehensive textbook covers the fundamental principles and models underlying the theory, algorithms and systems aspects of distributed computing. Broad and detailed coverage of the theory is balanced with practical systems-related issues such as mutual exclusion, deadlock detection, authentication, and failure recovery. Algorithms are carefully selected, lucidly presented, and described without complex proofs. Simple explanations and illustrations are used to elucidate the algorithms. Important emerging topics such as peer-to-peer networks and network security are also considered. With vital algorithms, numerous illustrations, examples and homework problems, this textbook is suitable for advanced undergraduate and graduate students of electrical and computer engineering and computer science. Practitioners in data networking and sensor networks will also find this a valuable resource. Additional resources are available online at www.cambridge.org/9780521876346.},
	pagetotal = {755},
	publisher = {Cambridge University Press},
	author = {Kshemkalyani, Ajay D. and Singhal, Mukesh},
	date = {2011-03-03},
	langid = {english},
	note = {Google-Books-{ID}: G7SZ32dPuLgC},
	keywords = {Technology \& Engineering / Signals \& Signal Processing, Technology \& Engineering / Telecommunications},
}

@incollection{lamport_distributed_1990,
	title = {Distributed Computing: Models and Methods},
	isbn = {978-0-444-88074-1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444880741500238},
	shorttitle = {Distributed Computing},
	pages = {1157--1199},
	booktitle = {Formal Models and Semantics},
	publisher = {Elsevier},
	author = {Lamport, Leslie and Lynch, Nancy},
	urldate = {2023-05-14},
	date = {1990},
	langid = {english},
	doi = {10.1016/B978-0-444-88074-1.50023-8},
	file = {Lamport and Lynch - 1990 - Distributed Computing Models and Methods.pdf:/home/tar/Zotero/storage/DSLRU46E/Lamport and Lynch - 1990 - Distributed Computing Models and Methods.pdf:application/pdf},
}

@book{ahrens_analytic_2012,
	location = {Berlin, Heidelberg},
	title = {Analytic Methods of Sound Field Synthesis},
	isbn = {978-3-642-25742-1 978-3-642-25743-8},
	url = {https://link.springer.com/10.1007/978-3-642-25743-8},
	series = {T-Labs Series in Telecommunication Services},
	publisher = {Springer Berlin Heidelberg},
	author = {Ahrens, Jens},
	urldate = {2023-05-13},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-25743-8},
	file = {ahrens2012.pdf:/home/tar/Zotero/storage/UVLE568X/ahrens2012.pdf:application/pdf},
}

@report{noauthor_ieee_2018,
	title = {{IEEE} Standard for Ethernet ({IEEE} Std 802.3™-2018 (Revision of {IEEE} Std 802.3-2015)},
	url = {https://ieeexplore.ieee.org/document/8457469/},
	institution = {{IEEE}},
	urldate = {2023-05-11},
	date = {2018},
	doi = {10.1109/IEEESTD.2018.8457469},
	note = {{ISBN}: 9781504450904},
}

@report{noauthor_multimedia_1991,
	title = {Multimedia Programming Interface and Data Specifications 1.0},
	url = {https://www.mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/Docs/riffmci.pdf},
	date = {1991},
	file = {riffmci.pdf:/home/tar/Zotero/storage/HW4PZZHK/riffmci.pdf:application/pdf},
}

@article{metcalfe_ethernet_1976,
	title = {Ethernet: distributed packet switching for local computer networks},
	volume = {19},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/360248.360253},
	doi = {10.1145/360248.360253},
	shorttitle = {Ethernet},
	abstract = {Ethernet is a branching broadcast communication system for carrying digital data packets among locally distributed computing stations. The packet transport mechanism provided by Ethernet has been used to build systems which can be viewed as either local computer networks or loosely coupled multiprocessors. An Ethernet's shared communication facility, its Ether, is a passive broadcast medium with no central control. Coordination of access to the Ether for packet broadcasts is distributed among the contending transmitting stations using controlled statistical arbitration. Switching of packets to their destinations on the Ether is distributed among the receiving stations using packet address recognition. Design principles and implementation are described based on experience with an operating Ethernet of 100 nodes along a kilometer of coaxial cable. A model for estimating performance under heavy loads and a packet protocol for error controlled communication are included for completeness.},
	pages = {395--404},
	number = {7},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Metcalfe, Robert M. and Boggs, David R.},
	urldate = {2023-05-09},
	date = {1976-07},
	langid = {english},
	file = {Full Text PDF:/home/tar/Zotero/storage/D8JNCLQT/Metcalfe and Boggs - 1976 - Ethernet distributed packet switching for local c.pdf:application/pdf},
}

@inproceedings{hardman_reliable_1995,
	title = {Reliable Audio for Use Over the Internet},
	volume = {95},
	rights = {open},
	url = {https://web.archive.org/web/20160103083922/http://www.isoc.org/inet95/proceedings/PAPER/070/html/paper.html},
	abstract = {This paper investigates the current problems found with audio applications over the {MBONE} (Multi-cast Backbone Overlay)/Internet, and, based on preliminary studies, describes possible solutions. The authors describe how current audio applications work, and how this structure enables redundancy to be a viable solution to the problem of packet loss. The paper proposes the use of synthetic speech coding algorithms (vocoders) to provide redundancy; the algorithms produce a very low bit-rate stream, which used alone give very mechanical sounding speech. Preliminary experiments show that normal speech repaired with synthetic quality speech is intelligible, even for very high loss rates. The paper goes on to investigate how the redundancy might be included in an audio application for use over the Internet.
The application of this work is multimedia conferencing over the Internet. The work is based on experiences in multi-way multimedia conferencing demonstrations from Project {MICE} (Multimedia Integrated Conferencing for Europe) (using the popular tool `vat'), Project {ReLaTe} (Remote Language Teaching over {SuperJANET}), and preliminary experiments.

Experience has shown that the major problem with the {MBONE} for audio is one of packet loss. Packet loss occurs for a number of reasons: when routers become congested, when packets arrive too late to be played back, or when scheduling difficulties in a multi-tasking operating system occur.

Experience has also shown that packet loss is a persistent problem, and it can be expected to get worse. From a user's point of view, packet loss severely disrupts speech intelligibility, even for very low loss rates. Consequently, a solution which renders the speech intelligible at all loss rate levels is required. Intelligible speech in these situations can only be achieved using redundancy; a separate `stream' of speech is transmitted in addition to the primary information.

Audio for transmission over the {MBONE}/Internet has to be split into packets, which are then launched onto the network. At the receiver, the packets may be delivered out of order, or not at all, and packet arrival times are unpredictable. This means that a number of packets must be kept `in hand' during play-out, so that the receiver has chance to re-order packets, and to smooth out unpredictable packet arrival times. Whenever one or more packets are lost, silence is played. This leads to the familiar speech clipping effects currently heard over the Internet. The nature of the Internet (large packets) unfortunately means that packet loss has a serious effect on the intelligibility of speech.

This paper introduces a method of using cheap redundancy within the packets sent from the transmitter. The redundancy is synthetic speech, (Linear Predictive Coding), which, when split into packets only adds a very small amount of overhead to a packet. The redundancy is added later in the train of packets than the primary speech information, which means that the receiver, upon suffering the loss of the primary speech information, has the possibility of substituting something sensible in the output stream of speech, provided that the redundancy can be received.

Preliminary experiments have been carried out into the perception of speech repaired with a synthetic substitute. The experiments objectively measured speech intelligibility as well as performing subjective evaluations. The results show that this technique is very successful at repairing speech with large packet sizes and for very high loss rates (results were taken up to 40\%).

The paper also identifies how this technique might be used in a multi-cast audio tool for the {MBONE}, and describes the work that has been done towards the implementation of such a tool to reliably transfer speech across the Internet.},
	eventtitle = {{IINET}'95 Conference},
	pages = {171--178},
	booktitle = {Proceedings of {INET}},
	publisher = {The Internet Society},
	author = {Hardman, V. and Sasse, M. A. and Handley, M. and Watson, A.},
	urldate = {2022-12-15},
	date = {1995},
	note = {Meeting Name: {IINET}'95 Conference
Place: {USA}: Hawaii},
	file = {Full Text PDF:/home/tar/Zotero/storage/6MEMFQKE/Hardman et al. - 1995 - Reliable Audio for Use Over the Internet.pdf:application/pdf;Snapshot:/home/tar/Zotero/storage/ZAYLMFI6/1471388.html:text/html},
}

@article{ades_architecture_1987,
	title = {An architecture for integrated services on the local area network},
	author = {Ades, Stephen},
	date = {1987},
	langid = {english},
	file = {Ades - An architecture for integrated services on the loc.pdf:/home/tar/Zotero/storage/Q484D2JH/Ades - An architecture for integrated services on the loc.pdf:application/pdf},
}

@report{noauthor_ieee_2019,
	title = {{IEEE} Std 754™-2019 (Revision of {IEEE} Std 754-2008) {IEEE} Standard for Floating-Point Arithmetic},
	abstract = {This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
	date = {2019},
	langid = {english},
	file = {2019 - IEEE Std 754™-2019 (Revision of IEEE Std 754-2008).pdf:/home/tar/Zotero/storage/KT8LMS3R/2019 - IEEE Std 754™-2019 (Revision of IEEE Std 754-2008).pdf:application/pdf},
}

@report{noauthor_ieee_2008,
	title = {{IEEE} Std 754™-2008 (Revision of {IEEE} Std 754-1985), {IEEE} Standard for Floating-Point Arithmetic},
	abstract = {Abstract: This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
	date = {2008},
	langid = {english},
	file = {IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:/home/tar/Zotero/storage/UKGZ9FMM/IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:application/pdf},
}

@report{ieee_ieee_1985,
	title = {{IEEE} Standard for Binary Floating-Point Arithmetic},
	url = {http://ieeexplore.ieee.org/document/30711/},
	institution = {{IEEE}},
	author = {{IEEE}},
	urldate = {2023-05-08},
	date = {1985},
	doi = {10.1109/IEEESTD.1985.82928},
	note = {{ISBN}: 9780738111650},
	file = {ieee-standard-for-binary-floatingpoint-arithmetic.pdf:/home/tar/Zotero/storage/TVF4IXID/ieee-standard-for-binary-floatingpoint-arithmetic.pdf:application/pdf},
}

@article{cohen_holy_1981,
	title = {On Holy Wars and a Plea for Peace},
	volume = {14},
	issn = {1558-0814},
	doi = {10.1109/C-M.1981.220208},
	abstract = {Which bit should travel first? The bit from the big end or the bit from the little end? Can a war between Big Endians and Little Endians be avoided?},
	pages = {48--54},
	number = {10},
	journaltitle = {Computer},
	author = {Cohen, D.},
	date = {1981-10},
	note = {Conference Name: Computer},
	keywords = {Elementary particles, Libraries, Military computing, Satellites, Wires},
	file = {Cohen - 1981 - On Holy Wars and a Plea for Peace.pdf:/home/tar/Zotero/storage/8SQK493G/Cohen - 1981 - On Holy Wars and a Plea for Peace.pdf:application/pdf},
}

@online{noauthor_paul_nodate,
	title = {Paul Stoffregen describes I2S output setup},
	url = {https://forum.pjrc.com/threads/65229-Setting-up-custom-I2S-communication?p=263104&viewfull=1#post263104},
	urldate = {2023-05-04},
	file = {Setting up custom I2S communication:/home/tar/Zotero/storage/9HZXMKQ2/65229-Setting-up-custom-I2S-communication.html:text/html},
}

@article{noauthor_using_nodate,
	title = {Using Multi-Channel Feature of {SAI}},
	langid = {english},
	file = {Using Multi-Channel Feature of SAI.pdf:/home/tar/Zotero/storage/292HHLUS/Using Multi-Channel Feature of SAI.pdf:application/pdf},
}

@article{noauthor_imx_nodate,
	title = {i.{MX} {RT}1060 Processor Reference Manual},
	langid = {english},
	file = {i.MX RT1060 Processor Reference Manual.pdf:/home/tar/Zotero/storage/92428PSC/i.MX RT1060 Processor Reference Manual.pdf:application/pdf},
}

@article{hinton_digital_2020,
	title = {The Digital Audio Word Clock An Overview},
	author = {Hinton, Frank},
	date = {2020},
	langid = {english},
	file = {Hinton - 2020 - The Digital Audio Word Clock An Overview.pdf:/home/tar/Zotero/storage/I2KP93AQ/Hinton - 2020 - The Digital Audio Word Clock An Overview.pdf:application/pdf},
}

@online{noauthor_primer_nodate,
	title = {A Primer On Word Clock {\textbar} Focusrite Audio Engineering Ltd.},
	url = {https://pro.focusrite.com/a-primer-on-word-clock},
	urldate = {2023-05-04},
	file = {A Primer On Word Clock | Focusrite Audio Engineering Ltd.:/home/tar/Zotero/storage/K54UV5WA/a-primer-on-word-clock.html:text/html},
}

@inproceedings{burgess_techniques_1992,
	location = {Monteray California {USA}},
	title = {Techniques for low cost spatial audio},
	isbn = {978-0-89791-549-6},
	url = {https://dl.acm.org/doi/10.1145/142621.142628},
	doi = {10.1145/142621.142628},
	eventtitle = {{UIST} '92: User Interface Software Technology 92},
	pages = {53--59},
	booktitle = {Proceedings of the 5th annual {ACM} symposium on User interface software and technology},
	publisher = {{ACM}},
	author = {Burgess, David A.},
	urldate = {2023-04-11},
	date = {1992-12},
	langid = {english},
	file = {Submitted Version:/home/tar/Zotero/storage/J2PVFASR/Burgess - 1992 - Techniques for low cost spatial audio.pdf:application/pdf},
}

@misc{noauthor_configuring_nodate,
	title = {Configuring Precision Time Protocol ({PTP})},
	langid = {english},
	file = {Configuring Precision Time Protocol (PTP).pdf:/home/tar/Zotero/storage/S98GG2X6/Configuring Precision Time Protocol (PTP).pdf:application/pdf},
}

@incollection{nicol_sound_2017,
	title = {Sound Field},
	abstract = {This chapter presents general ideas about the sound field approach and its development, starting from coincident stereo microphone recording techniques introduced by A. D. Blumlein to Ambisonics and High Order Ambisonics ({HOA}). It then discusses capture methods, recording formats and reproduction of sound fields. The chapter was dedicated to sound field, which means that the main concern was the reproduction of an acoustic wave over an extended listening area. Three main questions were investigated: how to record, how to represent and how to reproduce a sound field. After an overview of the general concepts, these investigations were illustrated in the specific case of High Order Ambisonics ({HOA}) technology (microphones, format, encoding, decoding matrix, loudspeaker setup). Sound field recording techniques lead to a full and accurate representation of sound waves. Sound field properties are linked to all of the acoustic phenomena encountered by the sound wave from its point of origin to its point of observation.},
	pages = {276--310},
	booktitle = {Immersive Sound},
	publisher = {Routledge},
	author = {Nicol, Rozenn},
	date = {2017},
	note = {Num Pages: 35},
	file = {10.4324_9781315707525-10_chapterpdf.pdf:/home/tar/Zotero/storage/THU9WZI3/10.4324_9781315707525-10_chapterpdf.pdf:application/pdf},
}

@article{daniel_further_2003,
	title = {Further Investigations of High-Order Ambisonics and Wavefield Synthesis for Holophonic Sound Imaging},
	volume = {114},
	abstract = {Ambisonics and Wavefield Synthesis are two ways of rendering 3D audio, which both aim at physically reconstructing the sound field. Though they derive from distinct theoretical fundamentals, they have already been shown as equivalent under given assumptions. This paper further discusses their relationship by introducing new results regarding the coding and rendering of finite distance and enclosed sources. An updated view of the current knowledge is first given. A unified analysis of sound pickup and reproduction by mean of concentric transducer arrays then provides an insight into the spatial encoding and decoding properties. While merging the analysis tools of both techniques and investigating them on a common ground, general compromises are highlighted in terms of spatial aliasing, error and noise amplification.},
	journaltitle = {Audio Engineering Society Convention},
	author = {Daniel, Jerome and Moreau, Sebastien and Nicol, Rozenn},
	date = {2003},
	langid = {english},
	file = {Daniel et al. - 2003 - Further Investigations of High-Order Ambisonics an.pdf:/home/tar/Zotero/storage/G9SRE8X9/Daniel et al. - 2003 - Further Investigations of High-Order Ambisonics an.pdf:application/pdf},
}

@article{ward_reproduction_2001,
	title = {Reproduction of a plane-wave sound field using an array of loudspeakers},
	volume = {9},
	issn = {1558-2353},
	doi = {10.1109/89.943347},
	abstract = {Reproduction of a sound field is a fundamental problem in acoustic signal processing. In this paper, we use a spherical harmonics analysis to derive performance bounds on how well an array of loudspeakers can recreate a three-dimensional (3-D) plane-wave sound field within a spherical region of space. Specifically, we develop a relationship between the number of loudspeakers, the size of the reproduction sphere, the frequency range, and the desired accuracy. We also provide analogous results for the special case of reproduction of a two-dimensional (2-D) sound field. Results are verified through computer simulations.},
	pages = {697--707},
	number = {6},
	journaltitle = {{IEEE} Transactions on Speech and Audio Processing},
	author = {Ward, D.B. and Abhayapala, T.D.},
	date = {2001-09},
	note = {Conference Name: {IEEE} Transactions on Speech and Audio Processing},
	keywords = {Acoustic signal processing, Loudspeakers, Acoustic arrays, Application software, Array signal processing, Audio systems, Computer simulation, Frequency, Harmonic analysis, Two dimensional displays},
	file = {IEEE Xplore Abstract Record:/home/tar/Zotero/storage/Q325TY5I/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/tar/Zotero/storage/GYXNDEQK/Ward and Abhayapala - 2001 - Reproduction of a plane-wave sound field using an .pdf:application/pdf},
}

@online{noauthor_jerome_nodate,
	title = {Jérôme Daniel's {PhD} Thesis and Ppt Presentation: Download page},
	url = {http://gyronymo.free.fr/audio3D/download_Thesis_PwPt.html},
	urldate = {2023-04-09},
	file = {Jérôme Daniel's PhD Thesis and Ppt Presentation\: Download page:/home/tar/Zotero/storage/2XLQJ8WX/download_Thesis_PwPt.html:text/html},
}

@article{chafe_levels_2001,
	title = {Levels of temporal resolution in sonification of network performance},
	abstract = {The standard “ping” utility provides a momentary measurement of round trip time. Sequences of ping events are used to gather longer-term statistics about jitter and packet loss in order to describe the quality of service of a network path. A more ﬁnegrained tool is needed to evaluate paths which carry interactive media streams for collaborative environments. Natural interaction depends on obtaining consistent low-latency, low-jitter service, something which normally requires several ping “takes” to assess and even then only provides an averaged picture of quality of service. We have designed a stream-based method which directly displays the critical qualities to the ear by continuously driving a bidirectional connection to create sound waves. The network path itself becomes the acoustic medium which our probe sets into vibration. The granularity of this display better matches the time-scales of variance that are important in interactive applications (for example, bidirectional audio streams for long-distance musical collaboration or high-quality teleconference applications). The ear’s acuity for pitch ﬂuctuation and timbral constancy make this an unforgiving test.},
	journaltitle = {Proceedings of the 2001 International Conference on Auditory Display},
	author = {Chafe, Chris and Leistikow, Randal},
	date = {2001},
	langid = {english},
	file = {Chafe and Leistikow - 2001 - Levels of temporal resolution in sonification of n.pdf:/home/tar/Zotero/storage/BFKXHVWX/Chafe and Leistikow - 2001 - Levels of temporal resolution in sonification of n.pdf:application/pdf},
}

@article{winter_geometric_2018,
	title = {A Geometric Model for Spatial Aliasing in Wave Field Synthesis},
	journaltitle = {Proc. of German Annual Conference on Acoustics ({DAGA})},
	author = {Winter, F and Ahrens, J and Spors, S},
	date = {2018},
	langid = {english},
	file = {Winter et al. - 2018 - A Geometric Model for Spatial Aliasing in Wave Fie.pdf:/home/tar/Zotero/storage/RQDAZLD9/Winter et al. - 2018 - A Geometric Model for Spatial Aliasing in Wave Fie.pdf:application/pdf},
}

@article{frank_producing_2015,
	title = {Producing 3D Audio in Ambisonics},
	abstract = {Ambisonics is a 3D recording and playback method that is based on the representation of the sound ﬁeld excitation as a decomposition into spherical harmonics. This representation facilitates spatial sound production that is independent of the playback system. The adaptation to a given playback system (loudspeakers or motion-tracked headphones) is achieved by a suitable decoder.},
	journaltitle = {Audio Engineering Society Conference: 57th International Conference: The Future of Audio Entertainment Technology--Cinema, Television and the Internet},
	author = {Frank, Matthias and Zotter, Franz and Sontacchi, Alois},
	date = {2015},
	langid = {english},
	file = {Frank et al. - 2015 - Producing 3D Audio in Ambisonics.pdf:/home/tar/Zotero/storage/ZCXS2356/Frank et al. - 2015 - Producing 3D Audio in Ambisonics.pdf:application/pdf},
}

@inproceedings{fonseca_latency_2003-1,
	title = {Latency in Audio Ethernet Networks},
	url = {https://www.aes.org/e-lib/browse.cfm?elib=12555},
	abstract = {In a time, when several audio Ethernet networking solutions appears, an analysis of the latency of this kind of audio networks, have a fundamental role. Not only to discover the factors that could optimize them, but also to decide about the possibility or not to include an in-band synchronism signals.},
	eventtitle = {Audio Engineering Society Convention 114},
	publisher = {Audio Engineering Society},
	author = {Fonseca, Nuno and Monteiro, Edmundo},
	urldate = {2022-12-15},
	date = {2003-03-01},
	file = {Fonseca and Monteiro - 2003 - Latency in Audio Ethernet Networks.pdf:/home/tar/Zotero/storage/PPU8GENA/Fonseca and Monteiro - 2003 - Latency in Audio Ethernet Networks.pdf:application/pdf},
}

@book{roginska_immersive_2017,
	title = {Immersive Sound: The Art and Science of Binaural and Multi-Channel Audio},
	isbn = {978-1-317-48011-2},
	shorttitle = {Immersive Sound},
	abstract = {Immersive Sound: The Art and Science of Binaural and Multi-Channel Audio provides a comprehensive guide to multi-channel sound. With contributions from leading recording engineers, researchers, and industry experts, Immersive Sound includes an in-depth description of the physics and psychoacoustics of spatial audio as well as practical applications. Chapters include the history of 3D sound, binaural reproduction over headphones and loudspeakers, stereo, surround sound, height channels, object-based audio, soundfield (ambisonics), wavefield synthesis, and multi-channel mixing techniques. Knowledge of the development, theory, and practice of spatial and multi-channel sound is essential to those advancing the research and applications in the rapidly evolving fields of 3D sound recording, augmented and virtual reality, gaming, film sound, music production, and post-production.},
	pagetotal = {379},
	publisher = {Taylor \& Francis},
	author = {Roginska, Agnieszka and Geluso, Paul},
	date = {2017-10-17},
	langid = {english},
	note = {Google-Books-{ID}: {IGkPEAAAQBAJ}},
	keywords = {Technology \& Engineering / Acoustics \& Sound},
	file = {Roginska and Geluso - 2017 - Immersive Sound The Art and Science of Binaural a.pdf:/home/tar/Zotero/storage/U8PXWPDV/Roginska and Geluso - 2017 - Immersive Sound The Art and Science of Binaural a.pdf:application/pdf},
}

@misc{smith_digital_nodate,
	title = {Digital Audio Resampling Home Page},
	author = {Smith, Julius O.},
	file = {resample.pdf:/home/tar/Zotero/storage/QEBAYGDH/resample.pdf:application/pdf},
}

@article{pulkki_virtual_1997,
	title = {Virtual Sound Source Positioning Using Vector Base Amplitude Panning},
	volume = {45},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=7853},
	pages = {456--466},
	number = {6},
	journaltitle = {J. Audio Eng. Soc},
	author = {Pulkki, Ville},
	date = {1997},
	file = {article1.pdf:/home/tar/Zotero/storage/F7L6SFIW/article1.pdf:application/pdf},
}

@article{cofino_comparing_nodate,
	title = {Comparing Two Methods of Sound Spatialization: Vector-Based Amplitude Panning ({VBAP}) vs. Linear Panning ({LP})},
	abstract = {There is an interest in presenting the sound from “Screen Reader” programs used by blind individuals to access the World Wide Web in multiple virtual “auditory columns”, aiming to restore the perception of 2-dimensional placement of items on contemporary web pages. As a prelude to that application, this paper reports the experimental comparison of two forms of virtual placement of sounds over 5 positions, in front of a computer user. The results indicate that there is not a statistically significant difference in accuracy achieved by application of the Vector-Based Amplitude Panning ({VBAP}) or the Linear Panning ({LP}) methods.},
	author = {Cofino, Jonathan and Barreto, Armando and Adjouadi, Malek},
	langid = {english},
	file = {Cofino et al. - Comparing Two Methods of Sound Spatialization Vec.pdf:/home/tar/Zotero/storage/SUPVVAEG/Cofino et al. - Comparing Two Methods of Sound Spatialization Vec.pdf:application/pdf},
}

@online{noauthor_introduction_nodate,
	title = {Introduction to Sound Programming with {ALSA} {\textbar} Linux Journal},
	url = {https://www.linuxjournal.com/article/6735?page=0,1#N0x19ab2890.0x19ba78d8},
	urldate = {2023-03-08},
	file = {Introduction to Sound Programming with ALSA | Linux Journal:/home/tar/Zotero/storage/8V77CPZZ/6735.html:text/html},
}

@article{turchet_elk_2021,
	title = {Elk Audio {OS}: An Open Source Operating System for the Internet of Musical Things},
	volume = {2},
	issn = {2691-1914},
	url = {https://doi.org/10.1145/3446393},
	doi = {10.1145/3446393},
	shorttitle = {Elk Audio {OS}},
	abstract = {As the Internet of Musical Things ({IoMusT}) emerges, audio-specific operating systems ({OSs}) are required on embedded hardware to ease development and portability of {IoMusT} applications. Despite the increasing importance of {IoMusT} applications, in this article, we show that there is no {OS} able to fulfill the diverse requirements of {IoMusT} systems. To address such a gap, we propose the Elk Audio {OS} as a novel and open source {OS} in this space. It is a Linux-based {OS} optimized for ultra-low-latency and high-performance audio and sensor processing on embedded hardware, as well as for handling wireless connectivity to local and remote networks. Elk Audio {OS} uses the Xenomai real-time kernel extension, which makes it suitable for the most demanding of low-latency audio tasks. We provide the first comprehensive overview of Elk Audio {OS}, describing its architecture and the key components of interest to potential developers and users. We explain operational aspects like the configuration of the architecture and the control mechanisms of the internal sound engine, as well as the tools that enable an easier and faster development of connected musical devices. Finally, we discuss the implications of Elk Audio {OS}, including the development of an open source community around it.},
	pages = {12:1--12:18},
	number = {2},
	journaltitle = {{ACM} Transactions on Internet of Things},
	shortjournal = {{ACM} Trans. Internet Things},
	author = {Turchet, Luca and Fischione, Carlo},
	urldate = {2023-01-19},
	date = {2021-03-27},
	keywords = {embedded systems, Internet of Musical Things, smart musical instruments},
	file = {Full Text PDF:/home/tar/Zotero/storage/AMJN8RLH/Turchet and Fischione - 2021 - Elk Audio OS An Open Source Operating System for .pdf:application/pdf},
}

@inproceedings{carot_network_2007,
	title = {Network music performance-problems, approaches and perspectives},
	volume = {162},
	pages = {23--10},
	booktitle = {Proceedings of the “Music in the Global Village”-Conference, Budapest, Hungary},
	author = {Carôt, Alexander and Werner, Christian},
	date = {2007},
	file = {MITGV_AC_CW.pdf:/home/tar/Zotero/storage/TCQ2HDEI/MITGV_AC_CW.pdf:application/pdf},
}

@article{geier_object-based_2010,
	title = {Object-based Audio Reproduction and the Audio Scene Description Format},
	volume = {15},
	issn = {1355-7718, 1469-8153},
	url = {http://www.journals.cambridge.org/abstract_S1355771810000324},
	doi = {10.1017/S1355771810000324},
	pages = {219--227},
	number = {3},
	journaltitle = {Organised Sound},
	shortjournal = {Org. Sound},
	author = {Geier, Matthias and Ahrens, Jens and Spors, Sascha},
	urldate = {2023-01-17},
	date = {2010-12},
	langid = {english},
	file = {Geier et al. - 2010 - Object-based Audio Reproduction and the Audio Scen.pdf:/home/tar/Zotero/storage/9A35M9A6/Geier et al. - 2010 - Object-based Audio Reproduction and the Audio Scen.pdf:application/pdf},
}

@article{elen_whatever_1991,
	title = {Whatever happened to Ambisonics?},
	journaltitle = {{AudioMedia} Magazine, Nov},
	author = {Elen, Richard},
	date = {1991},
	file = {Elen - Whatever Happened to Ambisonics.pdf:/home/tar/Zotero/storage/UNJ7PYW5/Elen - Whatever Happened to Ambisonics.pdf:application/pdf},
}

@article{ward_personalization_2019,
	title = {Personalization in Object-based Audio for Accessibility: A Review of Advancements for Hearing Impaired Listeners},
	volume = {67},
	issn = {15494950},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=20496},
	doi = {10.17743/jaes.2019.0021},
	shorttitle = {Personalization in Object-based Audio for Accessibility},
	pages = {584--597},
	number = {7},
	journaltitle = {Journal of the Audio Engineering Society},
	shortjournal = {J. Audio Eng. Soc.},
	author = {Ward, Lauren and Shirley, Ben},
	urldate = {2023-01-14},
	date = {2019-08-14},
	langid = {english},
	file = {Ward and Shirley - 2019 - Personalization in Object-based Audio for Accessib.pdf:/home/tar/Zotero/storage/NA3BVUS7/Ward and Shirley - 2019 - Personalization in Object-based Audio for Accessib.pdf:application/pdf},
}

@article{xu_real-time_2000,
	title = {Real-Time Streaming of Multichannel Audio Data over Internet},
	volume = {48},
	url = {https://www.aes.org/e-lib/online/browse.cfm?elib=12056},
	abstract = {On 1999 September 26 a musical performance, taking place at {McGill} University, was transmitted to an audience at New York University over the Internet. While Internet streaming audio techologies have been in use for several years, what made this event unique was the audience's experience of uninterrupted, intermediate-quality multichannel audio ({AC}-3). In order to achieve this result, a custom system was developed employing both {TCP} and {UDP} protocols, and providing its own buffering and...},
	pages = {627--641},
	number = {7},
	journaltitle = {Journal of the Audio Engineering Society},
	shortjournal = {{JAES}},
	author = {Xu, Aoxiang and Woszczyk, Wieslaw and Settel, Zack and Pennycook, Bruce and Rowe, Robert and Galanter, Philip and Bary, Jeffreyn},
	urldate = {2023-01-13},
	date = {2000-07-01},
	note = {Publisher: Audio Engineering Society},
	file = {Cooperstock - Real Time Streaming of Multi-channel Audio Data ov.pdf:/home/tar/Zotero/storage/8W26ZNVQ/Cooperstock - Real Time Streaming of Multi-channel Audio Data ov.pdf:application/pdf},
}

@article{sporer_wave_2004,
	title = {Wave field Synthesis - Generation and Reproduction of Natural Sound Environments},
	abstract = {Since the early days of stereo good spatial sound impression had been limited to a small region, the so-called sweet spot. About 15 years ago the concept of wave ﬁeld synthesis ({WFS}) solving this problem has been invented at {TU} Delft, but due to its computational complexity it has not been used outside universities and research institutes. Today the progress of microelectronics makes a variety of applications of {WFS} possible, like themed environments, cinemas, and exhibition spaces. This paper will highlight the basics of {WFS} and discuss some of the solutions beyond the basics to make it work in applications.},
	author = {Sporer, Thomas},
	date = {2004},
	langid = {english},
	file = {Sporer - 2004 - Wave field Synthesis - Generation and Reproduction.pdf:/home/tar/Zotero/storage/QXL5E42W/Sporer - 2004 - Wave field Synthesis - Generation and Reproduction.pdf:application/pdf},
}

@inproceedings{adriaensen_controlling_2012,
	title = {Controlling adaptive resampling},
	abstract = {Combining audio components that use incoherent sample clocks requires adaptive resampling - the exact ratio of the sample frequencies is not known a priori and may also drift slowly over time. This situation arises when using two audio cards that don’t have a common word clock, or when exchanging audio signals over a network. Controlling the resampling algorithm in software can be diﬃcult as the available information (e.g. timestamps on blocks of audio samples) is usually inexact and very noisy. This paper analyses the problem and presents a possible solution.},
	booktitle = {Linux Audio Conference},
	author = {Adriaensen, Fons},
	date = {2012},
	langid = {english},
	file = {adapt-resamp-pres.pdf:/home/tar/Zotero/storage/FFDQSKAC/adapt-resamp-pres.pdf:application/pdf;Adriaensen - Controlling adaptive resampling.pdf:/home/tar/Zotero/storage/Y95JQS66/Adriaensen - Controlling adaptive resampling.pdf:application/pdf},
}

@online{noauthor_what_nodate,
	title = {What is Dante? {\textbar} Audinate {\textbar} Dante Pro {AV} Networking},
	url = {https://www.audinate.com/meet-dante/what-is-dante},
	shorttitle = {What is Dante?},
	abstract = {Dante transforms\&nbsp;audio and video\&nbsp;connectivity\&nbsp;
{AV} systems have traditionally required point-to-point physical connections between devices, resulting in cumbersome amounts of specialized, single-purpose cables that define where audio and video signals can go. Changes are labor-intensive and expensive, and noise and signal degradation are constant companions as distances grow. The result is systems that are difficult to [\&hellip;]},
	urldate = {2022-12-20},
	file = {Snapshot:/home/tar/Zotero/storage/P4ISK8JL/what-is-dante.html:text/html},
}

@article{belloch_performance_2021,
	title = {On the performance of a {GPU}-based {SoC} in a distributed spatial audio system},
	volume = {77},
	issn = {1573-0484},
	url = {https://doi.org/10.1007/s11227-020-03577-4},
	doi = {10.1007/s11227-020-03577-4},
	abstract = {Many current system-on-chip ({SoC}) devices are composed of low-power multicore processors combined with a small graphics accelerator (or {GPU}) offering a trade-off between computational capacity and low-power consumption. In this context, spatial audio methods such as wave field synthesis ({WFS}) can benefit from a distributed system composed of several {SoCs} that collaborate to tackle the high computational cost of rendering virtual sound sources. This paper aims at evaluating important aspects dealing with a distributed {WFS} implementation that runs over a network of Jetson Nano boards composed of embedded {GPU}-based {SoCs}: computational performance, energy efficiency, and synchronization issues. Our results show that the maximum efficiency is obtained when the {WFS} system operates the {GPU} frequency at 691.2 {MHz}, achieving 11 sources-per-Watt. Synchronization experiments using the {NTP} protocol show that the maximum initial delay of 10 ms between nodes does not prevent us from achieving high spatial sound quality.},
	pages = {6920--6935},
	number = {7},
	journaltitle = {The Journal of Supercomputing},
	shortjournal = {J Supercomput},
	author = {Belloch, Jose A. and Badía, José M. and Larios, Diego F. and Personal, Enrique and Ferrer, Miguel and Fuster, Laura and Lupoiu, Mihaita and Gonzalez, Alberto and León, Carlos and Vidal, Antonio M. and Quintana-Ortí, Enrique S.},
	urldate = {2022-12-20},
	date = {2021-07-01},
	langid = {english},
	keywords = {Embedded systems, {GPU}, Jetson Nano, Real time, Spatial audio, System-on-chip ({SoC}), Wave field synthesis},
	file = {Full Text PDF:/home/tar/Zotero/storage/DI8EM5XT/Belloch et al. - 2021 - On the performance of a GPU-based SoC in a distrib.pdf:application/pdf},
}

@inproceedings{pinero_feasibility_2017,
	title = {On the feasibility of personal audio systems over a network of distributed loudspeakers},
	doi = {10.23919/EUSIPCO.2017.8081707},
	abstract = {Personal audio reproduction systems deal with the creation of personal sound zones within a room without the necessity of using headphones. These systems use an array of loudspeakers and design the required filters at each loudspeaker in order to render the desired audio signal to each person in the room as free of interferences as possible. There are very interesting proposals in the literature that make use of circular or linear arrays, but in this paper we study the problem considering a network of distributed loudspeakers controlled by a set of acoustic nodes, which can exchange information through a network. We state the model of such a distributed system by considering the electro-acoustic paths between the loudspeakers and each microphone, and try to provide a minimum signal-to-interference-and-noise ratio ({SINR}) to each zone, but constraining the emitted power of the loudspeakers to a maximum value (avoiding annoying feedback effects). We make use of optimization techniques to decide if, given a distribution of the loudspeakers and a location of the personal sound zones within the room, the system will be feasible. Simulations are done to support the use of the proposed optimization techniques.},
	eventtitle = {2017 25th European Signal Processing Conference ({EUSIPCO})},
	pages = {2729--2733},
	booktitle = {2017 25th European Signal Processing Conference ({EUSIPCO})},
	author = {Piñero, G. and Botella, C. and de Diego, M. and Ferrer, M. and González, A.},
	date = {2017-08},
	note = {{ISSN}: 2076-1465},
	keywords = {Loudspeakers, Acoustics, Interference, Microphones, Optimization, Signal to noise ratio, Wireless communication},
	file = {IEEE Xplore Abstract Record:/home/tar/Zotero/storage/6FA2P7V8/8081707.html:text/html;Submitted Version:/home/tar/Zotero/storage/PNGTGL85/Piñero et al. - 2017 - On the feasibility of personal audio systems over .pdf:application/pdf},
}
