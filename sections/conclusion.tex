\section{Conclusion}\label{sec:conclusion}

In this article we have described an exploration of transmission of audio data
over computer networks, distributed computing and audio spatialisation.
A networked audio system was developed, strategies devised for
addressing challenges presented by distributed computing, and a distributed
spatial audio system was developed and deployed.
Evaluation of the system exposed the extent of the technical challenges
that confront it in its current form, and shed light on opportunities for
further development.
Perceptual testing revealed that it may offer performance sufficient to support
timing-critical sound field synthesis techniques.
The proposed system represents a milestone on the road towards an accessible
alternative to state of the art spatial and immersive audio installations.

It has been shown that a system of discrete computational entities can
communicate effectively over an ethernet network, exchanging audio and control
data in a scalable fashion via a UDP multicast group.
Though facing significant technical challenges, the foundational requirements of
such a system have been demonstrated, with encouraging results with regard to
spatial audio applications.

Timing discrepancies between entities in the networked audio system give rise
to audible artefacts such as time-varying comb-filtering.
Loss of synchronicity is difficult to measure and compensate for in real-time;
the extent of the resulting audible disturbances is unpredictable, and firmer
conclusions about their extent, and thresholds for their perceptibility should
ideally be sought.
The developed strategies for mitigation of asynchronicity call for further
refinement, or replacement with more sophisticated techniques.

Given its potential to disrupt the present situation with regard to spatial
audio installations, or complement it with a modular approach that could serve
more flexible and creative ends, it is hoped that scope will exist to develop
this work further.
A number of technical challenges remain, and questions with regard to the
fundamental characteristics of the various components of the devised system
stand unanswered.
From the level of audio hardware and driver software, to audio host and audio
buffer behaviour, to network QoS and the performance of network switches, to
the behaviour of the hardware platform, its processor and audio codec, plus its
software libraries \textemdash{} much that is typically taken for granted in the
development of embedded systems, and audio and networking applications, calls
for deeper investigation.

Each microcontroller generates a clock signal to deliver to its audio shield,
which, in a locally distributed setting, is rather redundant.
It may be possible to generate a single, authoritative clock on one node and
deliver that to all others in the system.
If this can be achieved, it would remedy the issue of clock drift, leaving only
jitter to be addressed.
Furthermore, Teensy is not the only platform worthy of consideration;
developments in microcontroller technology are to be expected, and suitable
devices supporting higher-quality audio than offered by Teensy may emerge.
One device considered only briefly here is the Raspberry Pi;
in principle it is priced comparably with the Teensy, and is supported by audio
breakout boards that can output 24-bit audio.
Improved bare metal support, including the creation of a \texttt{faust2circle}
tool, could make Raspberry Pi a significantly more attractive platform,
particularly in terms of memory and the dimensions of the sound fields that
could be synthesised.

With regard to audio spatialisation, a basic, linear, wave field synthesis
algorithm has been demonstrated here, implementing virtual primary sources.
WFS is capable of producing other types of sources, supporting nonlinear
speaker arrays, three-dimensional arrays, and more faithful models of
energy loss due to absorption.
There are many further avenues to pursue, including optimising any DSP
algorithms to best exploit the capabilities of what, in the shape of the
Teensy and other microcontroller systems, are very powerful platforms.
Further, and only given cursory treatment here, higher order ambisonics, subject
to an assessment of its suitability to parallelisation, remains as a worthy
target for implementation in future work.
