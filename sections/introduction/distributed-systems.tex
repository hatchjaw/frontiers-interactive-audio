\subsection{Distributed Audio Systems}\label{subsec:distributed-audio-systems}

%In the preceding sections we have described ways of transmitting audio data to a
%network of computers, identified a suitable computing platform for networked
%audio, and discussed various approaches to audio spatialisation.
%Our aim is to create a distributed system

As alluded to earlier in this section, our aim is to distribute the problem of
audio spatialisation, and it is worthwhile to revisit why this is the case.
In the broadest terms, a distributed system is \textit{``a collection of
independent entities that cooperate to solve a problem that cannot be
individually solved''}~\citep{kshemkalyani_distributed_2011}.
An ideal distributed system is characterised by: \textit{modularity}, being
comprised of separate, interchangeable entities; \textit{scalability}, being
extensible without incurring a performance penalty to the system as a whole,
and; \textit{improved performance/cost ratio}, since it can be constructed to
meet the proportion that circumstances require, with the minimum degree of
redundancy.
%Additionally, our ideal spatial audio system should be flexible and accessible,
%not being tied to any particular space.

Where a distributed system may suffer when compared with its centralised
equivalent is in terms of reliability.
Nodes in a distributed computational system must be served with power and access
to the data they require in order to operate, which entails a proliferation of
potential points of failure.
The other side to the coin of modularity is a concern regarding the
programmability of such a system;
ensuring that all entities possess up-to-date instructions for operation may not
be trivial.
Further, distributing an algorithm requires identifying a way to execute it in
parallel;
some algorithms may be better suited to parallelisation than others.

Distributed audio processing is by no means a matter without precedent.
(Indeed, the WFS installation at TU Berlin described in
\secref{subsubsec:spatial-sota} is of course a distributed system, albeit not
an especially accessible one.)
%In light of the manner in which it is built into the concert hall that it
%serves, and the high cost of the system as a whole, however, such a system is
%far from accessible.
A selection of prior work in distributed DSP and audio spatialisation, plus
systems incorporating microcontrollers and single-board computers is detailed
below.

\subsubsection{State of the Art Distributed Audio Systems}

Applications of SoundWIRE to what its creators termed \textit{Internet
Acoustics}~\citep{chafe_physical_2002} obviously represent a case of distributed
audio processing.
These include a network reverberator~\citep{chafe_i_2018}, or
\textit{``transcontinental echo chamber''}~\citep{chafe_simplified_2000},
plus the aforementioned \textit{Network Harp}.
Experiments of this sort were intended initially as sonifications of QoS
\textemdash{} a characteristic of network systems that is difficult to represent
in graphical or textual form due to the ephemeral nature of the phenomena of
jitter and packet loss \textemdash{} but stand as fascinating applications in
their own right of digital audio in the age of computer networking.
Subsequent work on JackTrip has focused on optimising networked audio less
for sound processing or as a creative tool in itself, and more in service of
the social and communal aspects of music participation and appreciation in a
networked world;
these are topics that came to the fore in computer music research during the
COVID 19 pandemic~\citep{bosi_experiencing_2021,sacchetto_jacktrip-webrtc_2021}.

Lago~\citep{lago_distributed_2004} proposed a UDP-based system for real-time
distributed audio processing taking the form of a network of general purpose
computers.
A server sent packets of audio data to be processed by a collection of
clients, which would then return processed audio to the server to be combined
and used for output.
Since clients were not to be used directly for output, synchronisation was not
important, but Lago identifies the timing or hardware based interrupts for
audio and network processing as being of great importance to a distributed
real-time implementation.
Though an interesting exploration of approaching certain difficulties of
distributed computing, DSP in particular, and ambitious for its time (2004),
arguably the need for such a system has been obviated by advances in computer
processing power over the succeeding two decades.

A digital music production system of networked Beagleboard single-board
computers was demonstrated by Gabrielli et al.~\citep{gabrielli_networked_2012}
Another ambitious project, particularly since it utilised wireless
communication, an example configuration consisted of three nodes, one sending
control data to another, which produced audio and transmitted it to the third,
which recorded it in a Digital Audio Workstation (DAW).
The authors were more concerned with latency than synchronicity for their
purposes, and measured latency via transmission round-trip times using a
sawtooth wave as a timer (see \secref{subsec:technical-evaluation} for an
application of this technique).

Exploring the possibilities of burgeoning network technology in the early 2010s,
Lopez-Lezcano set out to build a UDP-based ``network sound card'' to support
a networked WFS system~\citep{lopez-lezcano_jack_2012}.
The aim was to replace otherwise expensive high channel-count conventional
audio interfaces, which receive audio over the MADI (Multichannel Audio Digital
Interface) protocol, with a more cost-effective alternative.
Ultimately the devised system was not used for audio spatialisation, but
facilitated networked musical performance, and it stands as an example of the
results that can be achieved by using `raw' UDP data for audio transmission,
rather than an established protocol or system.

In addition to Gabrielli et al., implementations on IoT-like devices include
Chafe and Oshiro's port of JackTrip to the Raspberry Pi single-board computer
for further internet acoustics, plus distributed spatialisation systems such as
those described by Devonport and Foss~\citep{devonport_distribution_2019} and
Belloch et al.~\citep{belloch_performance_2021}
The latter two address aims closely aligned with the work described here, but
are based on costly computing platforms.
Devonport and Foss achieved high synchronicity via AVB; Belloch et al.\ used a
GPU-based hardware platform, which is perhaps unsuited to its task, and report
client synchronisation to the millisecond range \textemdash{} likely not
sufficient for timing-critical audio spatialisation effects.

Also of interest is the OTTOsonics~\citep{mitterhuber_ottosonics_2022}
project;
its emphasis on a fully-costed, flexible, do-it-yourself alternative to
conventional spatial audio systems is pertinent to this work, though it diverges
in its use of AVB, and associated hardware for audio transmission.
A full 24-channel OTTOsonics system, including speakers and audio interface, is
costed at around \texteuro{2600} (\texteuro{108.33}/channel), however, which
certainly places it favourably when compared with state-of-the-art
spatialisation systems.

\subsubsection{Challenges}\label{subsubsec:challenges}

In addition to the problems of programmability, and effective parallelisation,
time, especially when dealing with the fine margins posed by real-time audio
processing, represents the principal source of difficulty in a distributed
audio setting.

\textit{Jitter} refers to fluctuations in the rate of transmission or
processing.
In a networked audio setting, jitter gives rise to a situation whereby the
arrival of audio data does not correspond with the moments at which it is
needed.
In a naive implementation, this may result in a recipient either halting
processing until it receives the expected data, or simply continuing without
any data.
In either case, the result is likely to be disruption of the integrity of the
audio signal in the form of audible discontinuities.

\textit{Clock drift} arises as an inevitable consequence of no source of time
in a system of computation being perfectly uniform, and no two sources of time
being identical.
The timing of a computer system is typically governed by a crystal oscillator,
the accuracy of which is affected by factors such as ambient temperature, and
potentially computational load on the system it
governs~\citep{marouani_internal_2008}.
Relative drift (sometimes, within the diagnostic parts of JackTrip for example,
referred to as \textit{skew}), is the difference in clock rates between two or
more systems.
Whereas jitter is a short-term phenomenon, clock drift typically takes effect
over a longer timescale.
As two distinct systems of time move in and out of phase with each other over
the longer term, drift may indeed give rise to jitter.

In professional audio settings, devices may be synchronised via an authoritative
clock source such as word clock, or, in a networked setting, via PTP or
lower-resolution network time protocol.
In the absence of such an authoritative source, e.g.\ over a wide area network,
or if using hardware that does not support such measures, buffering strategies
are typically employed, coupled with delay-locked
loops and resampling~\citep{adriaensen_using_2005, adriaensen_controlling_2012}.
